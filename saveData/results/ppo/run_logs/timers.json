{
    "name": "root",
    "gauges": {
        "DriveToTarget.Policy.Entropy.mean": {
            "value": 1.4154407978057861,
            "min": 1.4150630235671997,
            "max": 1.4275223016738892,
            "count": 10
        },
        "DriveToTarget.Policy.Entropy.sum": {
            "value": 70650.3125,
            "min": 70650.3125,
            "max": 71616.203125,
            "count": 10
        },
        "DriveToTarget.Environment.EpisodeLength.mean": {
            "value": 62.86895674300254,
            "min": 42.048611111111114,
            "max": 62.86895674300254,
            "count": 10
        },
        "DriveToTarget.Environment.EpisodeLength.sum": {
            "value": 49415.0,
            "min": 48440.0,
            "max": 49639.0,
            "count": 10
        },
        "DriveToTarget.Step.mean": {
            "value": 499946.0,
            "min": 49986.0,
            "max": 499946.0,
            "count": 10
        },
        "DriveToTarget.Step.sum": {
            "value": 499946.0,
            "min": 49986.0,
            "max": 499946.0,
            "count": 10
        },
        "DriveToTarget.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.27496734261512756,
            "min": -0.5378132462501526,
            "max": 3.879225015640259,
            "count": 10
        },
        "DriveToTarget.Policy.ExtrinsicValueEstimate.sum": {
            "value": -341.5094299316406,
            "min": -764.2326049804688,
            "max": 5733.49462890625,
            "count": 10
        },
        "DriveToTarget.Environment.CumulativeReward.mean": {
            "value": -0.5881749394589101,
            "min": -0.842290102140889,
            "max": -0.5881749394589101,
            "count": 10
        },
        "DriveToTarget.Environment.CumulativeReward.sum": {
            "value": -462.30550241470337,
            "min": -969.4759075641632,
            "max": -462.30550241470337,
            "count": 10
        },
        "DriveToTarget.Policy.ExtrinsicReward.mean": {
            "value": -0.5881749394589101,
            "min": -0.842290102140889,
            "max": -0.5881749394589101,
            "count": 10
        },
        "DriveToTarget.Policy.ExtrinsicReward.sum": {
            "value": -462.30550241470337,
            "min": -969.4759075641632,
            "max": -462.30550241470337,
            "count": 10
        },
        "DriveToTarget.Losses.PolicyLoss.mean": {
            "value": 0.024634555621693532,
            "min": 0.022197551594581456,
            "max": 0.02817349430173635,
            "count": 10
        },
        "DriveToTarget.Losses.PolicyLoss.sum": {
            "value": 0.12317277810846766,
            "min": 0.1035197384073399,
            "max": 0.14086747150868176,
            "count": 10
        },
        "DriveToTarget.Losses.ValueLoss.mean": {
            "value": 0.13833834543824194,
            "min": 0.1344976347560684,
            "max": 5.684315002957979,
            "count": 10
        },
        "DriveToTarget.Losses.ValueLoss.sum": {
            "value": 0.6916917271912097,
            "min": 0.5379905390242736,
            "max": 22.737260011831918,
            "count": 10
        },
        "DriveToTarget.Policy.LearningRate.mean": {
            "value": 1.6492894502399998e-05,
            "min": 1.6492894502399998e-05,
            "max": 0.00028459635513455,
            "count": 10
        },
        "DriveToTarget.Policy.LearningRate.sum": {
            "value": 8.246447251199999e-05,
            "min": 8.246447251199999e-05,
            "max": 0.0012844794718401998,
            "count": 10
        },
        "DriveToTarget.Policy.Epsilon.mean": {
            "value": 0.1054976,
            "min": 0.1054976,
            "max": 0.19486545,
            "count": 10
        },
        "DriveToTarget.Policy.Epsilon.sum": {
            "value": 0.527488,
            "min": 0.5000636,
            "max": 0.9281598,
            "count": 10
        },
        "DriveToTarget.Policy.Beta.mean": {
            "value": 0.00028433023999999997,
            "min": 0.00028433023999999997,
            "max": 0.004743785955,
            "count": 10
        },
        "DriveToTarget.Policy.Beta.sum": {
            "value": 0.0014216511999999998,
            "min": 0.0014216511999999998,
            "max": 0.02141517402,
            "count": 10
        },
        "DriveToTarget.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "DriveToTarget.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1742847563",
        "python_version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\mmmba\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\mlagents-learn --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1742848126"
    },
    "total": 563.3336395998485,
    "count": 1,
    "self": 0.011641099816188216,
    "children": {
        "run_training.setup": {
            "total": 0.07563470001332462,
            "count": 1,
            "self": 0.07563470001332462
        },
        "TrainerController.start_learning": {
            "total": 563.246363800019,
            "count": 1,
            "self": 1.6083659613505006,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.21884260000661,
                    "count": 1,
                    "self": 7.21884260000661
                },
                "TrainerController.advance": {
                    "total": 554.3248857387807,
                    "count": 63218,
                    "self": 1.3984812770504504,
                    "children": {
                        "env_step": {
                            "total": 412.6480151016731,
                            "count": 63218,
                            "self": 349.04732737876475,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 62.57363040023483,
                                    "count": 63218,
                                    "self": 4.340593764325604,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 58.23303663590923,
                                            "count": 55572,
                                            "self": 58.23303663590923
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.0270573226734996,
                                    "count": 63218,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 555.275500925025,
                                            "count": 63218,
                                            "is_parallel": true,
                                            "self": 290.1076115986798,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.000300500076264143,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 8.420017547905445e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00021629990078508854,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00021629990078508854
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 265.1675888262689,
                                                    "count": 63218,
                                                    "is_parallel": true,
                                                    "self": 6.882165089249611,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.458116616122425,
                                                            "count": 63218,
                                                            "is_parallel": true,
                                                            "self": 9.458116616122425
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 233.55520299333148,
                                                            "count": 63218,
                                                            "is_parallel": true,
                                                            "self": 233.55520299333148
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 15.272104127565399,
                                                            "count": 63218,
                                                            "is_parallel": true,
                                                            "self": 6.087230114964768,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 9.18487401260063,
                                                                    "count": 126436,
                                                                    "is_parallel": true,
                                                                    "self": 9.18487401260063
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 140.2783893600572,
                            "count": 63218,
                            "self": 2.178986875806004,
                            "children": {
                                "process_trajectory": {
                                    "total": 46.58842478389852,
                                    "count": 63218,
                                    "self": 46.511284983716905,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.07713980018161237,
                                            "count": 1,
                                            "self": 0.07713980018161237
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 91.51097770035267,
                                    "count": 48,
                                    "self": 60.84611340472475,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 30.664864295627922,
                                            "count": 1440,
                                            "self": 30.664864295627922
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.800013706088066e-06,
                    "count": 1,
                    "self": 1.800013706088066e-06
                },
                "TrainerController._save_models": {
                    "total": 0.09426769986748695,
                    "count": 1,
                    "self": 0.04182139993645251,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.052446299931034446,
                            "count": 1,
                            "self": 0.052446299931034446
                        }
                    }
                }
            }
        }
    }
}